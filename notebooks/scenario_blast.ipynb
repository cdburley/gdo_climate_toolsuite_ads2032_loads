{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd40f4f4-5a80-40b7-94b3-aed136daa9d8",
   "metadata": {},
   "source": [
    "# Demonstrate the Ability to Pass Mulitple Weather Years Through the WECC 2032 ADS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e597e9-538f-41d4-afa9-a268b10ab1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the packages we need:\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f6fe5-0769-4298-887e-7c4cffc64a0d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd887600-32da-46dc-b411-fa63c75f564f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the top-level directory and the subdirectory where the data will be stored:\n",
    "ads_load_data_dir =  '/Users/burl878/Documents/Code/code_repos/gdo_climate_toolsuite_ads2032_loads/data/'\n",
    "tell_load_data_dir = '/Users/burl878/Documents/Code/code_repos/gdo_climate_toolsuite_ads2032_loads/data/TELL_Loads/'\n",
    "image_output_dir =  '/Users/burl878/Documents/Code/code_repos/gdo_climate_toolsuite_ads2032_loads/plots/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169dc070-0ab8-4833-b6a0-589869ebf64e",
   "metadata": {},
   "source": [
    "## Process the Peak Load Magnitude and Date for Each Weather Year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abe13f-ec5f-4ee2-919c-e53a3037239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process the extract the peak demand value and time for each year:\n",
    "def process_peak_load_magnitude_and_date(ads_load_data_dir: str, tell_load_data_dir: str):\n",
    "    \n",
    "    #Initiate a counter and empty dataframe to store the results:\n",
    "    counter = 1;\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    # Read in the raw data .csv file for the 2032 ADS data:\n",
    "    gv_df = pd.read_csv((ads_load_data_dir + '2032ADS_EEI_Format_Data.csv'))\n",
    "\n",
    "    # Subset to just hourly demand by BA, drop the index column, and convert the values to floats:\n",
    "    gv_df = gv_df[1:8785]\n",
    "    del gv_df[\"Index\"]\n",
    "    gv_df = gv_df.astype(np.float64)\n",
    "    \n",
    "    # Sum the loads across BAs by hour and convert the value from MW to GW:\n",
    "    gv_df['Total_Load_GW'] = ((gv_df.sum(axis=1)) / 1000).round(2)\n",
    "\n",
    "    # Reset the index column:\n",
    "    gv_df = gv_df.reset_index()\n",
    "\n",
    "    # Put the output in a new dataframe:\n",
    "    output_df.loc[counter, 'Source'] = 'ADS'\n",
    "    output_df.loc[counter, 'Weather_Year'] = 2018\n",
    "    output_df.loc[counter, 'Total_Load_TWh'] = ((gv_df['Total_Load_GW'].sum()) / 1000).round(2)\n",
    "    output_df.loc[counter, 'Peak_Load_GW'] = gv_df['Total_Load_GW'].max()\n",
    "    output_df.loc[counter, 'Peak_Day'] = ((gv_df['index'].loc[gv_df['Total_Load_GW'].idxmax()])/24).round(2)\n",
    "\n",
    "    # Clean up and move to the TELL loads:\n",
    "    del gv_df\n",
    "    \n",
    "    # Loop over the years of TELL load data:\n",
    "    for year in range(1980,2025,1):\n",
    "        # Iterate the counter by one:\n",
    "        counter = counter + 1\n",
    "        \n",
    "        # Read in the raw data .csv file for the TELL weather year:\n",
    "        gv_df = pd.read_csv((tell_load_data_dir + 'TELL_Loads_2032_Based_on_' + str(year) + '_Weather.csv'))\n",
    "\n",
    "        # Subset to just hourly demand by BA, drop the index column, and convert the values to floats:\n",
    "        gv_df = gv_df[1:8761]\n",
    "        del gv_df[\"Index\"]\n",
    "        gv_df = gv_df.astype(np.float64)\n",
    "    \n",
    "        # Sum the loads across BAs by hour and convert the value from MW to GW:\n",
    "        gv_df['Total_Load_GW'] = ((gv_df.sum(axis=1)) / 1000).round(2)\n",
    "\n",
    "        # Reset the index column:\n",
    "        gv_df = gv_df.reset_index()\n",
    "\n",
    "        # Put the output in a new dataframe:\n",
    "        output_df.loc[counter, 'Source'] = 'TELL'\n",
    "        output_df.loc[counter, 'Weather_Year'] = year\n",
    "        output_df.loc[counter, 'Total_Load_TWh'] = ((gv_df['Total_Load_GW'].sum()) / 1000).round(2)\n",
    "        output_df.loc[counter, 'Peak_Load_GW'] = gv_df['Total_Load_GW'].max()\n",
    "        output_df.loc[counter, 'Peak_Day'] = ((gv_df['index'].loc[gv_df['Total_Load_GW'].idxmax()])/24).round(2)\n",
    "    \n",
    "        # Clean up and move to the next year:\n",
    "        del gv_df\n",
    "        \n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f968d55-90de-4578-a430-cfdb7c11ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the peak demand value and time for each year:\n",
    "output_df = process_peak_load_magnitude_and_date(ads_load_data_dir = ads_load_data_dir, \n",
    "                                                 tell_load_data_dir = tell_load_data_dir)\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f60cb-bd17-4cbf-8ebe-2498d5ff7c67",
   "metadata": {},
   "source": [
    "## Make the Double Distribution Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029cce8b-4b97-4aeb-9e26-40f78a4d5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to just the year 2019:\n",
    "ads_df = output_df.loc[output_df['Source'] == 'ADS'].copy()\n",
    "tell_2018_df = output_df.loc[(output_df['Source'] == 'TELL') & (output_df['Weather_Year'] == 2018)].copy()\n",
    "\n",
    "# Make the plot:\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.scatter(output_df['Peak_Day'], output_df['Peak_Load_GW'], s=100, c='blue', label = 'TELL (1980-2024)')\n",
    "plt.scatter(ads_df['Peak_Day'], ads_df['Peak_Load_GW'], s=100, c='red', label = 'Base 2032 ADS (2018)')\n",
    "plt.scatter(tell_2018_df['Peak_Day'], tell_2018_df['Peak_Load_GW'], s=100, c='green', label = 'TELL (2018)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xticks([1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335],['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.xticks(rotation = 45)\n",
    "plt.xlim([151, 275])\n",
    "plt.ylim([170, 190])\n",
    "plt.xlabel('Day of the Year for Peak Demand')\n",
    "plt.ylabel('Peak Demand in the WECC [GW]')\n",
    "plt.title('Interannual Variability in Peak Demand in the WECC')\n",
    "\n",
    "plt.savefig(os.path.join(image_output_dir, ('WECC_Peak_Demand_Distribution.png')), dpi=300, bbox_inches='tight', facecolor='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3f764-9ae3-4d1e-bf34-6686c93ae885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tell",
   "language": "python",
   "name": "tell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
